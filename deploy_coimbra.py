# -*- coding: utf-8 -*-
"""Deploy Coimbra.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rXyszOZxEyuvpiesHhLR4bVWSqF9JEx8
"""

!pip install streamlit -q

!streamlit --version

!pip install xgboost==1.0.0

import xgboost==1.0.0

from google.colab import files
uploaded = files.upload()

#RANDOM FOREST + XGBOOST
from xgboost import XGBRFClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import RandomForestClassifier
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
import io
import xgboost
from xgboost import XGBClassifier
from xgboost import plot_tree
import time
start = time.time()

dataset = pd.read_csv(io.BytesIO(uploaded['dataR2.csv']))
X = dataset.drop('Classification', axis=1)
y = dataset['Classification']

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.25, random_state=1)

XGBO=  XGBClassifier(booster ='gbtree', num_parallel_tree = 100,max_depth=12,random_state=3)
XGBO.fit(X_train,y_train)

y_pred = XGBO.predict(X_test)

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test,y_pred)
print(cm)

from sklearn.metrics import roc_auc_score
print('AUC = %.2f' % roc_auc_score(y_test, y_pred))  

from sklearn.metrics import confusion_matrix
print(confusion_matrix(y_test, y_pred), ": is the confusion matrix")
from sklearn.metrics import accuracy_score
print(accuracy_score(y_test, y_pred), ": is the accuracy score")
from sklearn.metrics import precision_score
print(precision_score(y_test, y_pred), ": is the precision score")
from sklearn.metrics import recall_score
print(recall_score(y_test, y_pred), ": is the recall score")
from sklearn.metrics import f1_score
print(f1_score(y_test, y_pred), ": is the f1 score")
end = time.time()
print(end - start, "seconds")

#RANDOM FOREST + XGBOOST
from xgboost import XGBRFClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import RandomForestClassifier
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
import io
import xgboost
from xgboost import XGBClassifier
from xgboost import plot_tree
import time
start = time.time()

dataset = pd.read_csv(io.BytesIO(uploaded['dataR2.csv']))
X = dataset.drop('Classification', axis=1)
y = dataset['Classification']

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.25, random_state=1)

XGBO=  XGBClassifier(booster ='gbtree', num_parallel_tree = 100,max_depth=12,random_state=3)
XGBO.fit(X_train,y_train)

y_pred = XGBO.predict(X_test)

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test,y_pred)
print(cm)

from sklearn.metrics import roc_auc_score
print('AUC = %.2f' % roc_auc_score(y_test, y_pred))  

from sklearn.metrics import confusion_matrix
print(confusion_matrix(y_test, y_pred), ": is the confusion matrix")
from sklearn.metrics import accuracy_score
print(accuracy_score(y_test, y_pred), ": is the accuracy score")
from sklearn.metrics import precision_score
print(precision_score(y_test, y_pred), ": is the precision score")
from sklearn.metrics import recall_score
print(recall_score(y_test, y_pred), ": is the recall score")
from sklearn.metrics import f1_score
print(f1_score(y_test, y_pred), ": is the f1 score")
end = time.time()
print(end - start, "seconds")

!pip install xgboost==1.0.0

from google.colab import files
uploaded = files.upload()

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import pandas as pd
# from xgboost import XGBRFClassifier
# from sklearn.ensemble import AdaBoostClassifier
# from sklearn.ensemble import RandomForestClassifier
# import matplotlib.pyplot as plt
# from sklearn.metrics import confusion_matrix
# from numpy.core.numeric import True_
# from sklearn import metrics
# import numpy as np
# 
# from sklearn.preprocessing import LabelEncoder
# from sklearn.model_selection import train_test_split
# from sklearn.metrics import plot_confusion_matrix, plot_roc_curve, plot_precision_recall_curve
# from sklearn.metrics import precision_score, recall_score, accuracy_score
# 
# import seaborn as sns
# 
# from xgboost import XGBClassifier
# from xgboost import plot_tree
# 
# def main():
#     st.title('Introduction to building Streamlit WebApp')
#     st.sidebar.title('This is the sidebar')
#     st.sidebar.markdown('Let‚Äôs start with binary classification!')
# if __name__ == ‚Äò__main__‚Äô:
#     main()
# 
# @st.cache.data(persist= True)
# uploaded_file = st.file_uploader("Choose a file")
# if uploaded_file is not None:
#     uploaded_file.seek(0)
#     def load():
#     df = pd.read_csv(uploaded_file, low_memory=False)
#     label= LabelEncoder()
#     for i in data.columns:
#         data[i] = label.fit_transform(data[i])
# return data
# 
# df = load()
#     if st.sidebar.checkbox("Display data", False):
#     st.subheader("Show Mushroom dataset")
#     st.write(df)
# 
# 
# 
# X = df.drop('Classification', axis=1)
# y = df['Classification']
# st.header('Variabel X')
# st.write(X)
# 
# st.header('Variabel y')
# st.write(y)
# 
# from sklearn.model_selection import train_test_split
# X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.25, random_state=1)
# 
# XGBO= XGBClassifier(booster ='gbtree', num_parallel_tree = 100,max_depth=12,random_state=3)
# XGBO.fit(X_train,y_train)
# 
# 
# y_pred = XGBO.predict(X_test)
# 
# 
# st.header('Variabel y pred')
# st.write(y_pred)
# 
#

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import pandas as pd
# import numpy as np
# from sklearn.svm import SVC
# from sklearn.linear_model import LogisticRegression
# from sklearn.ensemble import RandomForestClassifier
# from sklearn.preprocessing import LabelEncoder
# from sklearn.model_selection import train_test_split
# from sklearn.metrics import ConfusionMatrixDisplay
# import matplotlib.pyplot as plt 
# from sklearn.metrics import roc_curve
# from sklearn.metrics import precision_recall_curve
# from sklearn.metrics import precision_score
# from sklearn.metrics import recall_score 
# from sklearn.metrics import accuracy_score
# 
# def main():
#     st.title("Binary Classification Web App")
#     st.sidebar.title("Binary Classification Web App")
#     st.markdown("Are your mushrooms edible or poisonous?üçÑ")
#     st.sidebar.markdown("Are your mushrooms edible or poisonous?üçÑ")
# 
# 
#     @st.cache_data(persist=True)
#     def load_data():
#         data = pd.read_csv('mushrom.csv')
#         label = LabelEncoder()
#         for col in data.columns:
#             data[col] = label.fit_transform(data[col])
#         return data
# 
#     @st.cache_data(persist=True)
#     def split(df):
#         y = df.type
#         x = df.drop(columns =['type'])
#         x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)
#         return x_train, x_test, y_train, y_test
# 
# 
#     def plot_metrics(metrics_list):
#         st.set_option('deprecation.showPyplotGlobalUse', False)
# 
# 
# 
#         if 'Confusion Matrix' in metrics_list:
#             st.subheader("Confusion Matrix") 
#             ConfusionMatrixDisplay(model, x_test, y_test, display_labels=class_names)
#             st.pyplot()
#         
#         if 'ROC Curve' in metrics_list:
#             st.subheader("ROC Curve") 
#             plot_roc_curve(model, x_test, y_test)
#             st.pyplot()
# 
#         if 'Precision-Recall Curve' in metrics_list:
#             st.subheader("Precision-Recall Curve")
#             plot_precision_recall_curve(model, x_test, y_test)
#             st.pyplot()
# 
# 
#     df = load_data()
#     class_names = ['edible', 'poisonous']
# 
#     x_train, x_test, y_train, y_test = split(df)
#     
#     st.sidebar.subheader("Choose Classifier")
#     classifier = st.sidebar.selectbox("Classifier", ("Support Vector Machine (SVM)", "Logistic Regression", "Random Forest"))
# 
#     if classifier == 'Support Vector Machine (SVM)':
#         st.sidebar.subheader("Model Hyperparameters")
#         C = st.sidebar.number_input("C (Regularizaion parameter)", 0.01, 10.0, step=0.01, key='C')
#         kernel = st.sidebar.radio("Kernel",("rbf", "linear"), key='kernel')
#         gamma = st.sidebar.radio("Gamma (Kernel Coefficient", ("scale", "auto"), key = 'gamma')
#         metrics = st.sidebar.multiselect("What metrics to plot?",('Confusion Matrix', 'ROC Curve', 'Precision-Recall Curve'))
# 
#         if st.sidebar.button("Classfiy", key='classify'):
#             st.subheader("Support Vector Machine (SVM Results")
#             model = SVC(C=C, kernel=kernel, gamma=gamma)
#             model.fit(x_train, y_train)
#             accuracy = model.score(x_test, y_test)
#             y_pred = model.predict(x_test)
#             st.write("Accuracy ", accuracy.round(2))
#             st.write("Precision: ", precision_score(y_test, y_pred, labels=class_names).round(2))
#             st.write("Recall: ", recall_score(y_test, y_pred, labels=class_names).round(2))
#             plot_metrics(metrics)
# 
#     if classifier == 'Logistic Regression':
#         st.sidebar.subheader("Model Hyperparameters")
#         C = st.sidebar.number_input("C (Regularizaion parameter)", 0.01, 10.0, step=0.01, key='C_LR')
#         max_iter = st.sidebar.slider("Maxiumum number of interations", 100, 500, key='max_iter')
#         metrics = st.sidebar.multiselect("What metrics to plot?",('Confusion Matrix', 'ROC Curve', 'Precision-Recall Curve'))
# 
#         if st.sidebar.button("Classfiy", key='classify'):
#             st.subheader("Logistic Regression Results")
#             model = LogisticRegression(C=C, max_iter=max_iter)
#             model.fit(x_train, y_train)
#             accuracy = model.score(x_test, y_test)
#             y_pred = model.predict(x_test)
#             st.write("Accuracy ", accuracy.round(2))
#             st.write("Precision: ", precision_score(y_test, y_pred, labels=class_names).round(2))
#             st.write("Recall: ", recall_score(y_test, y_pred, labels=class_names).round(2))
#             st.write("Accuracy score: ", accuracy_score(y_test, y_pred, labels=class_names).round(2))
#             plot_metrics(metrics)
# 
# 
# 
#     if classifier == 'Random Forest':
#         st.sidebar.subheader("Model Hyperparameters")
#         n_estimators  = st.sidebar.number_input("The number of trees in the forest", 100, 5000, step=10, key='n_estimators')
#         max_depth = st.sidebar.number_input("The maximum depth of the tree", 1, 20, step=1, key='max_depth')
#         bootstrap = st.sidebar.radio("Bootstrap samples when building trees", ('True','False'), key='bootstrap')
#         metrics = st.sidebar.multiselect("What metrics to plot?",('Confusion Matrix', 'ROC Curve', 'Precision-Recall Curve'))
# 
#         if st.sidebar.button("Classfiy", key='classify'):
#             st.subheader("")
#             model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, bootstrap=bootstrap, n_jobs=-1)
#             model.fit(x_train, y_train)
#             accuracy = model.score(x_test, y_test)
#             y_pred = model.predict(x_test)
#             st.write("Accuracy ", accuracy.round(2))
#             st.write("Precision: ", precision_score(y_test, y_pred, labels=class_names).round(2))
#             st.write("Recall: ", recall_score(y_test, y_pred, labels=class_names).round(2))
#             plot_metrics(metrics)
# 
# 
#     if st.sidebar.checkbox("Show raw data", False):
#         st.subheader("Mushroom Data Set (Classification)")
#         st.write(df)
# 
# 
# if __name__ == '__main__':
#     main()
#

=afasfasf
import streamlit as st
st.write ('# Hello World')
st.write('## Run Stereamlit `nrok` using')


from google.colab import files
uploaded = files.upload()

#RANDOM FOREST + XGBOOST
from xgboost import XGBRFClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import RandomForestClassifier
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
import io
from xgboost import XGBClassifier
from xgboost import plot_tree
import time
start = time.time()

dataset = pd.read_csv(io.BytesIO(uploaded['dataR2.csv']))
X = dataset.drop('Classification', axis=1)
y = dataset['Classification']

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.25, random_state=1)

XGBO=  XGBClassifier(booster ='gbtree', num_parallel_tree = 100,max_depth=12,random_state=3)
XGBO.fit(X_train,y_train)

y_pred = XGBO.predict(X_test)

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test,y_pred)
print(cm)

from sklearn.metrics import roc_auc_score
print('AUC = %.2f' % roc_auc_score(y_test, y_pred))  

from sklearn.metrics import confusion_matrix
print(confusion_matrix(y_test, y_pred), ": is the confusion matrix")
from sklearn.metrics import accuracy_score
print(accuracy_score(y_test, y_pred), ": is the accuracy score")
from sklearn.metrics import precision_score
print(precision_score(y_test, y_pred), ": is the precision score")
from sklearn.metrics import recall_score
print(recall_score(y_test, y_pred), ": is the recall score")
from sklearn.metrics import f1_score
print(f1_score(y_test, y_pred), ": is the f1 score")
end = time.time()
print(end - start, "seconds")

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# st.write ('# Hello World')
# st.write('## Run Stereamlit `nrok` using')

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import pandas as pd
# import numpy as np
# import sklearn
# from sklearn.svm import SVC
# from sklearn.linear_model import LogisticRegression
# from sklearn.ensemble import RandomForestClassifier
# from sklearn.preprocessing import LabelEncoder
# from sklearn.model_selection import train_test_split
# from sklearn.metrics import ConfusionMatrixDisplay
# import matplotlib.pyplot as plt 
# from sklearn.metrics import roc_curve
# from sklearn.metrics import precision_recall_curve
# from sklearn.metrics import precision_score
# from sklearn.metrics import recall_score 
# from sklearn.metrics import accuracy_score
# from xgboost import XGBRFClassifier
# from xgboost import XGBClassifier
# from sklearn.feature_selection import RFECV
# from sklearn.model_selection import StratifiedKFold
# 
# uploaded_file = st.file_uploader("Choose a file", key="1")
# if uploaded_file is not None:
#    uploaded_file.seek(0)
# 
# 
# def main():
#     st.title("Breast Cancer Classification Web App")
#     st.sidebar.title("Breast Cancer Classification Web App")
#     st.markdown("Are you have breast cancer?")
#     st.sidebar.markdown("Are you have breast cancer?")
# 
# 
# 
#      
# 
# 
# 
#     @st.cache_data(persist=True)
#     def load_data():
#         data = pd.read_csv(uploaded_file, low_memory=False)
#         label = LabelEncoder()
#         for col in data.columns:
#             data[col] = label.fit_transform(data[col])
#         return data
# 
#     @st.cache_data(persist=True)
#     def split(df):
#         y = df.Classification
#         x = df.drop(columns =['Classification'])
#         x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)
#         return x_train, x_test, y_train, y_test
# 
# 
#     @st.cache_data(persist=True)
#     def split(dfnew):
#         y = dfnew.Classification
#         x = dfnew.drop(columns =['Classification'])
#         x_train2, x_test2, y_train2, y_test2 = train_test_split(x, y, test_size=0.3, random_state=1)
#         return x_train2, x_test2, y_train2, y_test2
# 
# 
# 
# 
# 
#     def plot_metrics(metrics_list):
#         st.set_option('deprecation.showPyplotGlobalUse', False)
# 
# 
# 
#         if 'Confusion Matrix' in metrics_list:
#             st.subheader("Confusion Matrix") 
#             ConfusionMatrixDisplay(model, x_test, y_test, display_labels=class_names)
#             st.pyplot()
#         
#         if 'ROC Curve' in metrics_list:
#             st.subheader("ROC Curve") 
#             plot_roc_curve(model, x_test, y_test)
#             st.pyplot()
# 
#         if 'Precision-Recall Curve' in metrics_list:
#             st.subheader("Precision-Recall Curve")
#             plot_precision_recall_curve(model, x_test, y_test)
#             st.pyplot()
# 
#         if 'Seleksi Fitur' in metrics_list:
#             st.subheader("Seleksi Fitur")
#             plt.figure(figsize=(16, 14))
#             plt.barh(y=dset['attr'], width=dset['importance'], color='#1976D2')
#             plt.title('RFECV - Feature Importances', fontsize=20, fontweight='bold', pad=20)
#             plt.xlabel('Importance', fontsize=14, labelpad=20)
#             st.pyplot(plt.gcf())
#             
# 
# 
#     df = load_data()
#     class_names = ['Health Control', 'Patient']
# 
#     x_train, x_test, y_train, y_test = split(df)
# 
#     dfnew = load_data()
#     class_names = ['Health Control', 'Patient']
#     
#     x_train2, x_test2, y_train2, y_test2 = split(dfnew)
#         
#     
#     st.sidebar.subheader("Choose Classifier")
#     classifier = st.sidebar.selectbox("Classifier", ("Recursive Feature Elimination Cross Validation", "Random Forest", "Random Forest dengan XGBoost"), key="3")
# 
#     if classifier == 'Recursive Feature Elimination Cross Validation':
#         st.sidebar.subheader("Model Hyperparameters")
#         
# 
#         if st.sidebar.button("Classfiy", key='classify'):
#             st.subheader("Recursive Feature Elimination Cross Validation")
#             x_full = df.drop(columns =['Classification'])
#             y_full = df.Classification
#             rfc = RandomForestClassifier(random_state=0)
#             rfecv = RFECV(estimator=rfc, step=1, cv=StratifiedKFold(10), scoring='accuracy')
#             rfecv.fit(x_full, y_full)
#             x_full.drop(x_full.columns[np.where(rfecv.support_ == False)[0]], axis=1, inplace=True)
#             dset = pd.DataFrame()
#             dset['attr'] = x_full.columns
#             dset['importance'] = rfecv.estimator_.feature_importances_
#             dset = dset.sort_values(by='importance', ascending=False)
#             plot_metrics('Seleksi Fitur')
# 
# 
# 
#     if classifier == 'Random Forest':
#         st.sidebar.subheader("Model Hyperparameters")
#         n_estimators  = st.sidebar.number_input("The number of trees in the forest", 100, 5000, step=10, key='n_estimators')
#         max_depth = st.sidebar.number_input("The maximum depth of the tree", 1, 20, step=1, key='max_depth')
# 
# 
#         if st.sidebar.button("Classfiy", key='classify'):
#             st.subheader("Random Forest")
#             model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, n_jobs=-1, random_state=3)
#             model.fit(x_train, y_train)
#             accuracy = model.score(x_test, y_test)
#             y_pred = model.predict(x_test)
#             st.write("Accuracy ", accuracy.round(7))
#             st.write("Precision: ", precision_score(y_test, y_pred, labels=class_names).round(7))
#             st.write("Recall: ", recall_score(y_test, y_pred, labels=class_names).round(7))
# 
#     if classifier == 'Random Forest dengan XGBoost':
#         st.sidebar.subheader("Model Hyperparameters")
#         num_parallel_tree = st.sidebar.number_input("The number of trees in the forest", 100, 200, step=10, key='num_parallel_tree')
#         max_depth = st.sidebar.number_input("The maximum depth of the tree", 1, 20, step=1, key='max_depth')
# 
#         
#         if st.sidebar.button("Classfiy", key='classify'):
#             st.subheader("Random Forest dengan XGBoost")
#             model = XGBClassifier(num_parallel_tree=num_parallel_tree, max_depth=max_depth, n_jobs=-1)
#             model.fit(x_train, y_train)
#             accuracy = model.score(x_test, y_test)
#             y_pred = model.predict(x_test)
#             st.write("Accuracy ", accuracy.round(7))
#             st.write("Precision: ", precision_score(y_test, y_pred, labels=class_names).round(7))
#             st.write("Recall: ", recall_score(y_test, y_pred, labels=class_names).round(7))
# 
#     if st.sidebar.checkbox("Pilih Data", False, key='lihat2'):
#         st.subheader("Pilih data coimbra data set (Classification)")
#         st.write(df)
#         with st.form('form'):
#           sel_column = st.multiselect('Select column', df.columns,
#           help='Select a column to form a new dataframe. Press submit when done.')
#           drop_na = st.checkbox('Drop rows with missing value', value=True)
#           submitted = st.form_submit_button("Submit")
#     
#     if submitted:
#         dfnew = df[sel_column]
#         if drop_na:
#             dfnew = dfnew.dropna()
# 
#         st.write('New dataframe')
#         st.dataframe(dfnew)
# 
#     
#     @st.cache_data(persist=True)
#     def split(dfnew):
#         y = dfnew.Classification
#         x = dfnew.drop(columns =['Classification'])
#         x_train2, x_test2, y_train2, y_test2 = train_test_split(x, y, test_size=0.3, random_state=0)
#         return x_train2, x_test2, y_train2, y_test2
# 
#     if st.sidebar.checkbox("Show raw data Sebelum", False, key='lihat1'):
#         st.subheader("coimbra data set (Classification)")
#         st.write(df)
# 
#     
#     if st.sidebar.checkbox("Lihat data baru", False, key='lihat3'):
#         st.subheader("coimbra data set (Classification)")
#         st.write(dfnew)
# 
#     if st.sidebar.checkbox("AKurasi Random Forest", False, key='lihat78'):
#         st.subheader("Random Forest")
#         model2 = RandomForestClassifier(n_estimators=10, max_depth=10,random_state=3)
#         model2.fit(x_train2, y_train2)
#         accuracy = model2.score(x_test2, y_test2)
#         y_pred2 = model2.predict(x_test2)
#         st.write("Accuracy ", accuracy.round(7))
#         st.write("Precision: ", precision_score(y_test2, y_pred2, labels=class_names).round(7))
#         st.write("Recall: ", recall_score(y_test2, y_pred2, labels=class_names).round(7))
#         st.write(dfnew)
# 
#     if st.sidebar.checkbox("Hasil baru", False, key='lihat80'):
#         st.subheader("Random Forest")
#         model2 = RandomForestClassifier(n_estimators=10, max_depth=10,random_state=3)
#         model2.fit(x_train2, y_train2)
#         Age = st.number_input("Masukan Umur") 
#         BMI = st.number_input("Masukan BMI") 
#         Restitin = st.number_input("Restitin") 
#         Glucose = st.number_input("Glucose")
#         hasil_1 = model2.predict(Age, BMI, Restitin, Glucose)
#         st.write(hasil_1)
# 
# 
# 
# 
# if __name__ == '__main__':
#     main()
#

! pip install pyngrok

from pyngrok import ngrok

!nohup streamlit run app.py &
url = ngrok.connect(port = '8501')
print(url)

!streamlit run app.py & npx localtunnel --port 8501