{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pi43HDvVTL5G",
        "outputId": "20256f62-0c41-4fee-f488-0a963e70b78f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.8/164.8 KB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 KB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsxWQQ8UNmfx",
        "outputId": "a56a4840-b68e-4225-8416-d3d1adab4e41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Streamlit, version 1.21.0\n"
          ]
        }
      ],
      "source": [
        "!streamlit --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaMPf-LSOy1B",
        "outputId": "6a73c906-fa7d-4657-aeab-12bf9eae1723"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting xgboost==1.0.0\n",
            "  Downloading xgboost-1.0.0-py3-none-manylinux1_x86_64.whl (109.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.7/109.7 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from xgboost==1.0.0) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from xgboost==1.0.0) (1.10.1)\n",
            "Installing collected packages: xgboost\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 1.7.5\n",
            "    Uninstalling xgboost-1.7.5:\n",
            "      Successfully uninstalled xgboost-1.7.5\n",
            "Successfully installed xgboost-1.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install xgboost==1.0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "tjDqJyUa25N3",
        "outputId": "4cfcdeaf-3213-4f56-c328-e8e0c2e6dfb7"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-803eac257246>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    import xgboost==1.0.0\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "import xgboost==1.0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "Zv0EHsVJO96q",
        "outputId": "965eaf30-6621-47db-8d4d-9b37ce997570"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ce0bd1ca-5cb5-4831-8c57-7a94c98bc619\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ce0bd1ca-5cb5-4831-8c57-7a94c98bc619\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving dataR2.csv to dataR2.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aS-u_ovCPDX_",
        "outputId": "e6478b53-1f82-40d4-f37d-12f83a3b04cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 7  2]\n",
            " [ 4 16]]\n",
            "AUC = 0.79\n",
            "[[ 7  2]\n",
            " [ 4 16]] : is the confusion matrix\n",
            "0.7931034482758621 : is the accuracy score\n",
            "0.6363636363636364 : is the precision score\n",
            "0.7777777777777778 : is the recall score\n",
            "0.7000000000000001 : is the f1 score\n",
            "0.701939582824707 seconds\n"
          ]
        }
      ],
      "source": [
        "#RANDOM FOREST + XGBOOST\n",
        "from xgboost import XGBRFClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import io\n",
        "import xgboost\n",
        "from xgboost import XGBClassifier\n",
        "from xgboost import plot_tree\n",
        "import time\n",
        "start = time.time()\n",
        "\n",
        "dataset = pd.read_csv(io.BytesIO(uploaded['dataR2.csv']))\n",
        "X = dataset.drop('Classification', axis=1)\n",
        "y = dataset['Classification']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.25, random_state=1)\n",
        "\n",
        "XGBO=  XGBClassifier(booster ='gbtree', num_parallel_tree = 100,max_depth=12,random_state=3)\n",
        "XGBO.fit(X_train,y_train)\n",
        "\n",
        "y_pred = XGBO.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "print(cm)\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "print('AUC = %.2f' % roc_auc_score(y_test, y_pred))  \n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(y_test, y_pred), \": is the confusion matrix\")\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(y_test, y_pred), \": is the accuracy score\")\n",
        "from sklearn.metrics import precision_score\n",
        "print(precision_score(y_test, y_pred), \": is the precision score\")\n",
        "from sklearn.metrics import recall_score\n",
        "print(recall_score(y_test, y_pred), \": is the recall score\")\n",
        "from sklearn.metrics import f1_score\n",
        "print(f1_score(y_test, y_pred), \": is the f1 score\")\n",
        "end = time.time()\n",
        "print(end - start, \"seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtzMV6prO8rQ"
      },
      "outputs": [],
      "source": [
        "#RANDOM FOREST + XGBOOST\n",
        "from xgboost import XGBRFClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import io\n",
        "import xgboost\n",
        "from xgboost import XGBClassifier\n",
        "from xgboost import plot_tree\n",
        "import time\n",
        "start = time.time()\n",
        "\n",
        "dataset = pd.read_csv(io.BytesIO(uploaded['dataR2.csv']))\n",
        "X = dataset.drop('Classification', axis=1)\n",
        "y = dataset['Classification']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.25, random_state=1)\n",
        "\n",
        "XGBO=  XGBClassifier(booster ='gbtree', num_parallel_tree = 100,max_depth=12,random_state=3)\n",
        "XGBO.fit(X_train,y_train)\n",
        "\n",
        "y_pred = XGBO.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "print(cm)\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "print('AUC = %.2f' % roc_auc_score(y_test, y_pred))  \n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(y_test, y_pred), \": is the confusion matrix\")\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(y_test, y_pred), \": is the accuracy score\")\n",
        "from sklearn.metrics import precision_score\n",
        "print(precision_score(y_test, y_pred), \": is the precision score\")\n",
        "from sklearn.metrics import recall_score\n",
        "print(recall_score(y_test, y_pred), \": is the recall score\")\n",
        "from sklearn.metrics import f1_score\n",
        "print(f1_score(y_test, y_pred), \": is the f1 score\")\n",
        "end = time.time()\n",
        "print(end - start, \"seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eODK3-O1AV7H",
        "outputId": "a777caee-dca1-465a-ee86-a30e5160bc01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: xgboost==1.0.0 in /usr/local/lib/python3.9/dist-packages (1.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from xgboost==1.0.0) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from xgboost==1.0.0) (1.10.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install xgboost==1.0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIlI79K8AYPc"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2-5-VyKH8tm",
        "outputId": "4034f44b-ec34-4d56-e8b0-d4f7a4c2c06b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "from xgboost import XGBRFClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from numpy.core.numeric import True_\n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import plot_confusion_matrix, plot_roc_curve, plot_precision_recall_curve\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from xgboost import plot_tree\n",
        "\n",
        "def main():\n",
        "    st.title('Introduction to building Streamlit WebApp')\n",
        "    st.sidebar.title('This is the sidebar')\n",
        "    st.sidebar.markdown('Let’s start with binary classification!')\n",
        "if __name__ == ‘__main__’:\n",
        "    main()\n",
        "\n",
        "@st.cache.data(persist= True)\n",
        "uploaded_file = st.file_uploader(\"Choose a file\")\n",
        "if uploaded_file is not None:\n",
        "    uploaded_file.seek(0)\n",
        "    def load():\n",
        "    df = pd.read_csv(uploaded_file, low_memory=False)\n",
        "    label= LabelEncoder()\n",
        "    for i in data.columns:\n",
        "        data[i] = label.fit_transform(data[i])\n",
        "return data\n",
        "\n",
        "df = load()\n",
        "    if st.sidebar.checkbox(\"Display data\", False):\n",
        "    st.subheader(\"Show Mushroom dataset\")\n",
        "    st.write(df)\n",
        "\n",
        "\n",
        "\n",
        "X = df.drop('Classification', axis=1)\n",
        "y = df['Classification']\n",
        "st.header('Variabel X')\n",
        "st.write(X)\n",
        "\n",
        "st.header('Variabel y')\n",
        "st.write(y)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.25, random_state=1)\n",
        "\n",
        "XGBO= XGBClassifier(booster ='gbtree', num_parallel_tree = 100,max_depth=12,random_state=3)\n",
        "XGBO.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "y_pred = XGBO.predict(X_test)\n",
        "\n",
        "\n",
        "st.header('Variabel y pred')\n",
        "st.write(y_pred)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEdr_98ee8bR",
        "outputId": "a9f81fcb-a225-4db2-e628-03a1f6e54798"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt \n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score \n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def main():\n",
        "    st.title(\"Binary Classification Web App\")\n",
        "    st.sidebar.title(\"Binary Classification Web App\")\n",
        "    st.markdown(\"Are your mushrooms edible or poisonous?🍄\")\n",
        "    st.sidebar.markdown(\"Are your mushrooms edible or poisonous?🍄\")\n",
        "\n",
        "\n",
        "    @st.cache_data(persist=True)\n",
        "    def load_data():\n",
        "        data = pd.read_csv('mushrom.csv')\n",
        "        label = LabelEncoder()\n",
        "        for col in data.columns:\n",
        "            data[col] = label.fit_transform(data[col])\n",
        "        return data\n",
        "\n",
        "    @st.cache_data(persist=True)\n",
        "    def split(df):\n",
        "        y = df.type\n",
        "        x = df.drop(columns =['type'])\n",
        "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)\n",
        "        return x_train, x_test, y_train, y_test\n",
        "\n",
        "\n",
        "    def plot_metrics(metrics_list):\n",
        "        st.set_option('deprecation.showPyplotGlobalUse', False)\n",
        "\n",
        "\n",
        "\n",
        "        if 'Confusion Matrix' in metrics_list:\n",
        "            st.subheader(\"Confusion Matrix\") \n",
        "            ConfusionMatrixDisplay(model, x_test, y_test, display_labels=class_names)\n",
        "            st.pyplot()\n",
        "        \n",
        "        if 'ROC Curve' in metrics_list:\n",
        "            st.subheader(\"ROC Curve\") \n",
        "            plot_roc_curve(model, x_test, y_test)\n",
        "            st.pyplot()\n",
        "\n",
        "        if 'Precision-Recall Curve' in metrics_list:\n",
        "            st.subheader(\"Precision-Recall Curve\")\n",
        "            plot_precision_recall_curve(model, x_test, y_test)\n",
        "            st.pyplot()\n",
        "\n",
        "\n",
        "    df = load_data()\n",
        "    class_names = ['edible', 'poisonous']\n",
        "\n",
        "    x_train, x_test, y_train, y_test = split(df)\n",
        "    \n",
        "    st.sidebar.subheader(\"Choose Classifier\")\n",
        "    classifier = st.sidebar.selectbox(\"Classifier\", (\"Support Vector Machine (SVM)\", \"Logistic Regression\", \"Random Forest\"))\n",
        "\n",
        "    if classifier == 'Support Vector Machine (SVM)':\n",
        "        st.sidebar.subheader(\"Model Hyperparameters\")\n",
        "        C = st.sidebar.number_input(\"C (Regularizaion parameter)\", 0.01, 10.0, step=0.01, key='C')\n",
        "        kernel = st.sidebar.radio(\"Kernel\",(\"rbf\", \"linear\"), key='kernel')\n",
        "        gamma = st.sidebar.radio(\"Gamma (Kernel Coefficient\", (\"scale\", \"auto\"), key = 'gamma')\n",
        "        metrics = st.sidebar.multiselect(\"What metrics to plot?\",('Confusion Matrix', 'ROC Curve', 'Precision-Recall Curve'))\n",
        "\n",
        "        if st.sidebar.button(\"Classfiy\", key='classify'):\n",
        "            st.subheader(\"Support Vector Machine (SVM Results\")\n",
        "            model = SVC(C=C, kernel=kernel, gamma=gamma)\n",
        "            model.fit(x_train, y_train)\n",
        "            accuracy = model.score(x_test, y_test)\n",
        "            y_pred = model.predict(x_test)\n",
        "            st.write(\"Accuracy \", accuracy.round(2))\n",
        "            st.write(\"Precision: \", precision_score(y_test, y_pred, labels=class_names).round(2))\n",
        "            st.write(\"Recall: \", recall_score(y_test, y_pred, labels=class_names).round(2))\n",
        "            plot_metrics(metrics)\n",
        "\n",
        "    if classifier == 'Logistic Regression':\n",
        "        st.sidebar.subheader(\"Model Hyperparameters\")\n",
        "        C = st.sidebar.number_input(\"C (Regularizaion parameter)\", 0.01, 10.0, step=0.01, key='C_LR')\n",
        "        max_iter = st.sidebar.slider(\"Maxiumum number of interations\", 100, 500, key='max_iter')\n",
        "        metrics = st.sidebar.multiselect(\"What metrics to plot?\",('Confusion Matrix', 'ROC Curve', 'Precision-Recall Curve'))\n",
        "\n",
        "        if st.sidebar.button(\"Classfiy\", key='classify'):\n",
        "            st.subheader(\"Logistic Regression Results\")\n",
        "            model = LogisticRegression(C=C, max_iter=max_iter)\n",
        "            model.fit(x_train, y_train)\n",
        "            accuracy = model.score(x_test, y_test)\n",
        "            y_pred = model.predict(x_test)\n",
        "            st.write(\"Accuracy \", accuracy.round(2))\n",
        "            st.write(\"Precision: \", precision_score(y_test, y_pred, labels=class_names).round(2))\n",
        "            st.write(\"Recall: \", recall_score(y_test, y_pred, labels=class_names).round(2))\n",
        "            st.write(\"Accuracy score: \", accuracy_score(y_test, y_pred, labels=class_names).round(2))\n",
        "            plot_metrics(metrics)\n",
        "\n",
        "\n",
        "\n",
        "    if classifier == 'Random Forest':\n",
        "        st.sidebar.subheader(\"Model Hyperparameters\")\n",
        "        n_estimators  = st.sidebar.number_input(\"The number of trees in the forest\", 100, 5000, step=10, key='n_estimators')\n",
        "        max_depth = st.sidebar.number_input(\"The maximum depth of the tree\", 1, 20, step=1, key='max_depth')\n",
        "        bootstrap = st.sidebar.radio(\"Bootstrap samples when building trees\", ('True','False'), key='bootstrap')\n",
        "        metrics = st.sidebar.multiselect(\"What metrics to plot?\",('Confusion Matrix', 'ROC Curve', 'Precision-Recall Curve'))\n",
        "\n",
        "        if st.sidebar.button(\"Classfiy\", key='classify'):\n",
        "            st.subheader(\"\")\n",
        "            model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, bootstrap=bootstrap, n_jobs=-1)\n",
        "            model.fit(x_train, y_train)\n",
        "            accuracy = model.score(x_test, y_test)\n",
        "            y_pred = model.predict(x_test)\n",
        "            st.write(\"Accuracy \", accuracy.round(2))\n",
        "            st.write(\"Precision: \", precision_score(y_test, y_pred, labels=class_names).round(2))\n",
        "            st.write(\"Recall: \", recall_score(y_test, y_pred, labels=class_names).round(2))\n",
        "            plot_metrics(metrics)\n",
        "\n",
        "\n",
        "    if st.sidebar.checkbox(\"Show raw data\", False):\n",
        "        st.subheader(\"Mushroom Data Set (Classification)\")\n",
        "        st.write(df)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tp0xdjJG_79G"
      },
      "outputs": [],
      "source": [
        "=afasfasf\n",
        "import streamlit as st\n",
        "st.write ('# Hello World')\n",
        "st.write('## Run Stereamlit `nrok` using')\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "#RANDOM FOREST + XGBOOST\n",
        "from xgboost import XGBRFClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import io\n",
        "from xgboost import XGBClassifier\n",
        "from xgboost import plot_tree\n",
        "import time\n",
        "start = time.time()\n",
        "\n",
        "dataset = pd.read_csv(io.BytesIO(uploaded['dataR2.csv']))\n",
        "X = dataset.drop('Classification', axis=1)\n",
        "y = dataset['Classification']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.25, random_state=1)\n",
        "\n",
        "XGBO=  XGBClassifier(booster ='gbtree', num_parallel_tree = 100,max_depth=12,random_state=3)\n",
        "XGBO.fit(X_train,y_train)\n",
        "\n",
        "y_pred = XGBO.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "print(cm)\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "print('AUC = %.2f' % roc_auc_score(y_test, y_pred))  \n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(y_test, y_pred), \": is the confusion matrix\")\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(y_test, y_pred), \": is the accuracy score\")\n",
        "from sklearn.metrics import precision_score\n",
        "print(precision_score(y_test, y_pred), \": is the precision score\")\n",
        "from sklearn.metrics import recall_score\n",
        "print(recall_score(y_test, y_pred), \": is the recall score\")\n",
        "from sklearn.metrics import f1_score\n",
        "print(f1_score(y_test, y_pred), \": is the f1 score\")\n",
        "end = time.time()\n",
        "print(end - start, \"seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wj5W5MK2RrOV"
      },
      "outputs": [],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "st.write ('# Hello World')\n",
        "st.write('## Run Stereamlit `nrok` using')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F55IYPrawecM",
        "outputId": "3bed5849-f344-41a2-b7f6-787366dcd290"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt \n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score \n",
        "from sklearn.metrics import accuracy_score\n",
        "from xgboost import XGBRFClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Choose a file\", key=\"1\")\n",
        "if uploaded_file is not None:\n",
        "   uploaded_file.seek(0)\n",
        "\n",
        "\n",
        "def main():\n",
        "    st.title(\"Breast Cancer Classification Web App\")\n",
        "    st.sidebar.title(\"Breast Cancer Classification Web App\")\n",
        "    st.markdown(\"Are you have breast cancer?\")\n",
        "    st.sidebar.markdown(\"Are you have breast cancer?\")\n",
        "\n",
        "\n",
        "\n",
        "     \n",
        "\n",
        "\n",
        "\n",
        "    @st.cache_data(persist=True)\n",
        "    def load_data():\n",
        "        data = pd.read_csv(uploaded_file, low_memory=False)\n",
        "        label = LabelEncoder()\n",
        "        for col in data.columns:\n",
        "            data[col] = label.fit_transform(data[col])\n",
        "        return data\n",
        "\n",
        "    @st.cache_data(persist=True)\n",
        "    def split(df):\n",
        "        y = df.Classification\n",
        "        x = df.drop(columns =['Classification'])\n",
        "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
        "        return x_train, x_test, y_train, y_test\n",
        "\n",
        "\n",
        "    @st.cache_data(persist=True)\n",
        "    def split(dfnew):\n",
        "        y = dfnew.Classification\n",
        "        x = dfnew.drop(columns =['Classification'])\n",
        "        x_train2, x_test2, y_train2, y_test2 = train_test_split(x, y, test_size=0.3, random_state=1)\n",
        "        return x_train2, x_test2, y_train2, y_test2\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def plot_metrics(metrics_list):\n",
        "        st.set_option('deprecation.showPyplotGlobalUse', False)\n",
        "\n",
        "\n",
        "\n",
        "        if 'Confusion Matrix' in metrics_list:\n",
        "            st.subheader(\"Confusion Matrix\") \n",
        "            ConfusionMatrixDisplay(model, x_test, y_test, display_labels=class_names)\n",
        "            st.pyplot()\n",
        "        \n",
        "        if 'ROC Curve' in metrics_list:\n",
        "            st.subheader(\"ROC Curve\") \n",
        "            plot_roc_curve(model, x_test, y_test)\n",
        "            st.pyplot()\n",
        "\n",
        "        if 'Precision-Recall Curve' in metrics_list:\n",
        "            st.subheader(\"Precision-Recall Curve\")\n",
        "            plot_precision_recall_curve(model, x_test, y_test)\n",
        "            st.pyplot()\n",
        "\n",
        "        if 'Seleksi Fitur' in metrics_list:\n",
        "            st.subheader(\"Seleksi Fitur\")\n",
        "            plt.figure(figsize=(16, 14))\n",
        "            plt.barh(y=dset['attr'], width=dset['importance'], color='#1976D2')\n",
        "            plt.title('RFECV - Feature Importances', fontsize=20, fontweight='bold', pad=20)\n",
        "            plt.xlabel('Importance', fontsize=14, labelpad=20)\n",
        "            st.pyplot(plt.gcf())\n",
        "            \n",
        "\n",
        "\n",
        "    df = load_data()\n",
        "    class_names = ['Health Control', 'Patient']\n",
        "\n",
        "    x_train, x_test, y_train, y_test = split(df)\n",
        "\n",
        "    dfnew = load_data()\n",
        "    class_names = ['Health Control', 'Patient']\n",
        "    \n",
        "    x_train2, x_test2, y_train2, y_test2 = split(dfnew)\n",
        "        \n",
        "    \n",
        "    st.sidebar.subheader(\"Choose Classifier\")\n",
        "    classifier = st.sidebar.selectbox(\"Classifier\", (\"Recursive Feature Elimination Cross Validation\", \"Random Forest\", \"Random Forest dengan XGBoost\"), key=\"3\")\n",
        "\n",
        "    if classifier == 'Recursive Feature Elimination Cross Validation':\n",
        "        st.sidebar.subheader(\"Model Hyperparameters\")\n",
        "        \n",
        "\n",
        "        if st.sidebar.button(\"Classfiy\", key='classify'):\n",
        "            st.subheader(\"Recursive Feature Elimination Cross Validation\")\n",
        "            x_full = df.drop(columns =['Classification'])\n",
        "            y_full = df.Classification\n",
        "            rfc = RandomForestClassifier(random_state=0)\n",
        "            rfecv = RFECV(estimator=rfc, step=1, cv=StratifiedKFold(10), scoring='accuracy')\n",
        "            rfecv.fit(x_full, y_full)\n",
        "            x_full.drop(x_full.columns[np.where(rfecv.support_ == False)[0]], axis=1, inplace=True)\n",
        "            dset = pd.DataFrame()\n",
        "            dset['attr'] = x_full.columns\n",
        "            dset['importance'] = rfecv.estimator_.feature_importances_\n",
        "            dset = dset.sort_values(by='importance', ascending=False)\n",
        "            plot_metrics('Seleksi Fitur')\n",
        "\n",
        "\n",
        "\n",
        "    if classifier == 'Random Forest':\n",
        "        st.sidebar.subheader(\"Model Hyperparameters\")\n",
        "        n_estimators  = st.sidebar.number_input(\"The number of trees in the forest\", 100, 5000, step=10, key='n_estimators')\n",
        "        max_depth = st.sidebar.number_input(\"The maximum depth of the tree\", 1, 20, step=1, key='max_depth')\n",
        "\n",
        "\n",
        "        if st.sidebar.button(\"Classfiy\", key='classify'):\n",
        "            st.subheader(\"Random Forest\")\n",
        "            model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, n_jobs=-1, random_state=3)\n",
        "            model.fit(x_train, y_train)\n",
        "            accuracy = model.score(x_test, y_test)\n",
        "            y_pred = model.predict(x_test)\n",
        "            st.write(\"Accuracy \", accuracy.round(7))\n",
        "            st.write(\"Precision: \", precision_score(y_test, y_pred, labels=class_names).round(7))\n",
        "            st.write(\"Recall: \", recall_score(y_test, y_pred, labels=class_names).round(7))\n",
        "\n",
        "    if classifier == 'Random Forest dengan XGBoost':\n",
        "        st.sidebar.subheader(\"Model Hyperparameters\")\n",
        "        num_parallel_tree = st.sidebar.number_input(\"The number of trees in the forest\", 100, 200, step=10, key='num_parallel_tree')\n",
        "        max_depth = st.sidebar.number_input(\"The maximum depth of the tree\", 1, 20, step=1, key='max_depth')\n",
        "\n",
        "        \n",
        "        if st.sidebar.button(\"Classfiy\", key='classify'):\n",
        "            st.subheader(\"Random Forest dengan XGBoost\")\n",
        "            model = XGBClassifier(num_parallel_tree=num_parallel_tree, max_depth=max_depth, n_jobs=-1)\n",
        "            model.fit(x_train, y_train)\n",
        "            accuracy = model.score(x_test, y_test)\n",
        "            y_pred = model.predict(x_test)\n",
        "            st.write(\"Accuracy \", accuracy.round(7))\n",
        "            st.write(\"Precision: \", precision_score(y_test, y_pred, labels=class_names).round(7))\n",
        "            st.write(\"Recall: \", recall_score(y_test, y_pred, labels=class_names).round(7))\n",
        "\n",
        "    if st.sidebar.checkbox(\"Pilih Data\", False, key='lihat2'):\n",
        "        st.subheader(\"Pilih data coimbra data set (Classification)\")\n",
        "        st.write(df)\n",
        "        with st.form('form'):\n",
        "          sel_column = st.multiselect('Select column', df.columns,\n",
        "          help='Select a column to form a new dataframe. Press submit when done.')\n",
        "          drop_na = st.checkbox('Drop rows with missing value', value=True)\n",
        "          submitted = st.form_submit_button(\"Submit\")\n",
        "    \n",
        "    if submitted:\n",
        "        dfnew = df[sel_column]\n",
        "        if drop_na:\n",
        "            dfnew = dfnew.dropna()\n",
        "\n",
        "        st.write('New dataframe')\n",
        "        st.dataframe(dfnew)\n",
        "\n",
        "    \n",
        "    @st.cache_data(persist=True)\n",
        "    def split(dfnew):\n",
        "        y = dfnew.Classification\n",
        "        x = dfnew.drop(columns =['Classification'])\n",
        "        x_train2, x_test2, y_train2, y_test2 = train_test_split(x, y, test_size=0.3, random_state=0)\n",
        "        return x_train2, x_test2, y_train2, y_test2\n",
        "\n",
        "    if st.sidebar.checkbox(\"Show raw data Sebelum\", False, key='lihat1'):\n",
        "        st.subheader(\"coimbra data set (Classification)\")\n",
        "        st.write(df)\n",
        "\n",
        "    \n",
        "    if st.sidebar.checkbox(\"Lihat data baru\", False, key='lihat3'):\n",
        "        st.subheader(\"coimbra data set (Classification)\")\n",
        "        st.write(dfnew)\n",
        "\n",
        "    if st.sidebar.checkbox(\"AKurasi Random Forest\", False, key='lihat78'):\n",
        "        st.subheader(\"Random Forest\")\n",
        "        model2 = RandomForestClassifier(n_estimators=10, max_depth=10,random_state=3)\n",
        "        model2.fit(x_train2, y_train2)\n",
        "        accuracy = model2.score(x_test2, y_test2)\n",
        "        y_pred2 = model2.predict(x_test2)\n",
        "        st.write(\"Accuracy \", accuracy.round(7))\n",
        "        st.write(\"Precision: \", precision_score(y_test2, y_pred2, labels=class_names).round(7))\n",
        "        st.write(\"Recall: \", recall_score(y_test2, y_pred2, labels=class_names).round(7))\n",
        "        st.write(dfnew)\n",
        "\n",
        "    if st.sidebar.checkbox(\"Hasil baru\", False, key='lihat80'):\n",
        "        st.subheader(\"Random Forest\")\n",
        "        model2 = RandomForestClassifier(n_estimators=10, max_depth=10,random_state=3)\n",
        "        model2.fit(x_train2, y_train2)\n",
        "        Age = st.number_input(\"Masukan Umur\") \n",
        "        BMI = st.number_input(\"Masukan BMI\") \n",
        "        Restitin = st.number_input(\"Restitin\") \n",
        "        Glucose = st.number_input(\"Glucose\")\n",
        "        hasil_1 = model2.predict(Age, BMI, Restitin, Glucose)\n",
        "        st.write(hasil_1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzsN9p_iTy0v",
        "outputId": "eafca68d-90e1-48c2-8a50-7bd18d7946e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-5.2.1.tar.gz (761 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m761.3/761.3 KB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from pyngrok) (6.0)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-5.2.1-py3-none-any.whl size=19790 sha256=431fba37e022c76037a286eadf39f5e256a74b5ce6fd5abdd4e014bb50f8be4d\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/89/59/49d4249e00957e94813ac136a335d10ed2e09a856c5096f95c\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-5.2.1\n"
          ]
        }
      ],
      "source": [
        "! pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIuA2JiW9isk"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WF5G40aY9saZ",
        "outputId": "58c3e576-dcf5-49ee-e60f-4681ebff6a85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n",
            "NgrokTunnel: \"http://a895-34-139-195-73.ngrok.io\" -> \"http://localhost:80\"\n"
          ]
        }
      ],
      "source": [
        "!nohup streamlit run app.py &\n",
        "url = ngrok.connect(port = '8501')\n",
        "print(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hf_TVF2F98--",
        "outputId": "06b73790-e31d-4abf-b20b-1639fc8e73d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[##................] / fetchMetadata: sill resolveWithNewModule ms@2.1.2 checki\u001b[0m\u001b[K\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8502\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.139.195.73:8502\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 4.119s\n",
            "your url is: https://pretty-bananas-think-34-139-195-73.loca.lt\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}